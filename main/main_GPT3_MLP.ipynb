{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a fine-tuning model specialized for Materials Science text mining \n",
    "\n",
    "Author: Jaewoong Choi (jwchoi95@kist.re.kr)\n",
    "\n",
    "Hello, this is a tutorial for applying GPT3 openAPI.\n",
    "\n",
    "\n",
    "\n",
    "Take in mind, as the use of openAPI is not free, this guideline is suggested for your efficient research.\n",
    "\n",
    "You have to do several things to use GPT3 API for your research.\n",
    "\n",
    "0. First of all, you have to gain the secret API key of openai. I can invite you in KIST group account or give you my key.\n",
    "\n",
    "1. The most important thing is the quality of input data and the relevance of unlabelled data.\n",
    "\n",
    "2. The quality of input data determines the performance of your fine-tuned model. If you have data with uncertain standard, the prediciton would be garbage.\n",
    "\n",
    "3. The relevance of unlabelled data is also important. Because the fine-tuned model is a kind of black-box model, if you give the model with unrelevant data, the model would be unable to judge it out of distribution. So, the filtering would be recommend before the prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If your openai is not working, try this\n",
    "\n",
    "Sometimes the older version is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==0.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The electrochemical performances of the Li/LiF...</td>\n",
       "      <td>ANODE: Li, CATHODE: LiFePO4, CATHODE: LiFePO4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The working electrode was fabricated by mixing...</td>\n",
       "      <td>CATHODE: working electrode, ACTIVE_MATERIAL: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The electrochemical properties of the LiFePO4/...</td>\n",
       "      <td>CATHODE: electrode, ACTIVE_MATERIAL: LiFePO4/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electrochemical performances of the materials ...</td>\n",
       "      <td>ANODE: metallic lithium film, SALT: LiPF6, SO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pouch shaped full cells with rated capacity of...</td>\n",
       "      <td>ANODE: graphite, ACTIVE_MATERIAL: cathode mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>In order to obtain the charge-discharge charac...</td>\n",
       "      <td>CONDUCTIVE_AGENT: acetylene black, BINDER: po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The performance of the Li(MnyFe1−y)PO4 cathode...</td>\n",
       "      <td>CATHODE: Li(MnyFe1−y)PO4 cathodes, ANODE: lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Thin film electrodes were manufactured for ele...</td>\n",
       "      <td>CURRENT_COLLECTOR: aluminium current collecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Electrochemical performance of various LiFePO4...</td>\n",
       "      <td>CATHODE: LiFePO4 electrodes, ANODE: metallic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The electrodes were fabricated using a mixture...</td>\n",
       "      <td>CATHODE: electrodes, CONDUCTIVE_AGENT: carbon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   The electrochemical performances of the Li/LiF...   \n",
       "1   The working electrode was fabricated by mixing...   \n",
       "2   The electrochemical properties of the LiFePO4/...   \n",
       "3   Electrochemical performances of the materials ...   \n",
       "4   Pouch shaped full cells with rated capacity of...   \n",
       "..                                                ...   \n",
       "95  In order to obtain the charge-discharge charac...   \n",
       "96  The performance of the Li(MnyFe1−y)PO4 cathode...   \n",
       "97  Thin film electrodes were manufactured for ele...   \n",
       "98  Electrochemical performance of various LiFePO4...   \n",
       "99  The electrodes were fabricated using a mixture...   \n",
       "\n",
       "                                           completion  \n",
       "0    ANODE: Li, CATHODE: LiFePO4, CATHODE: LiFePO4...  \n",
       "1    CATHODE: working electrode, ACTIVE_MATERIAL: ...  \n",
       "2    CATHODE: electrode, ACTIVE_MATERIAL: LiFePO4/...  \n",
       "3    ANODE: metallic lithium film, SALT: LiPF6, SO...  \n",
       "4    ANODE: graphite, ACTIVE_MATERIAL: cathode mat...  \n",
       "..                                                ...  \n",
       "95   CONDUCTIVE_AGENT: acetylene black, BINDER: po...  \n",
       "96   CATHODE: Li(MnyFe1−y)PO4 cathodes, ANODE: lit...  \n",
       "97   CURRENT_COLLECTOR: aluminium current collecto...  \n",
       "98   CATHODE: LiFePO4 electrodes, ANODE: metallic ...  \n",
       "99   CATHODE: electrodes, CONDUCTIVE_AGENT: carbon...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('your file')\n",
    "#len(df)\n",
    "#df.to_json(\"data.jsonl\", orient = 'records', lines =True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset preparation\n",
    "\n",
    "Training/validation is necessary, and test set is additional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 20, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.25, random_state=42)\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data as jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_json('val_df.jsonl', orient='records', lines=True)\n",
    "train_df.to_json('train_df.jsonl', orient='records', lines=True)\n",
    "test_df.to_json('test_df.jsonl', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"your key\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use openai tools for data preparation, which automatically transforms it into the computational form.\n",
    "\n",
    "Make the end token of prompt/completion.\n",
    "\n",
    "Lower is recommended, not necessary.\n",
    "\n",
    "Jsonl is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 60 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "- All prompts end with suffix `.==>\\n`\n",
      "- All completions end with suffix `\\n\\n###\\n\\n`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `train_df_prepared (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"train_df_prepared (1).jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `.==>\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\\n###\\n\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 3.27 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f train_df.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f val_df.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f test_df.jsonl -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model tranining with train/validation set\n",
    "0. Remember this is in-context learning.\n",
    "\n",
    "1. Model; davinci, ada, babbage, curie => the most important thing, test the site: https://gpttools.com/comparisontool.\n",
    "2. Batch size; how many data is used in a single training. default epochs 4.\n",
    "3. Prompt loss weight; how much the model tries to learn the prompt compared to completion.\n",
    "4. Learning rate; test 0.02~0.2 to find the best model.\n",
    "5. Compute_classification_metrics, classification_betas, classification_n_classes and classification_positive_class can be used, if you solve the categorical problem.\n",
    "6. You can add model name \"suffix\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t \"train_df_prepared.jsonl\" -v \"val_df_prepared.jsonl\" -m \"davinci\"  --batch_size 1 --n_epochs 4 --learning_rate_multiplier 0.01 --prompt_loss_weight 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training/validation performance monitoring can be implemented with Results module.\n",
    "\n",
    "This is not to fine the best parameters in our model.\n",
    "\n",
    "Just find the best-working model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.results -i \"model_name\" > result.csv\n",
    "#model_name = ft-sZDvr2RiPcbovKwXa5QkyF4V\n",
    "\n",
    "#results[results['classification/accuracy'].notnull()].tail(1)\n",
    "#results[results['classification/accuracy'].notnull()]['classification/accuracy'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use various functions as follows.\n",
    "\n",
    "You can find the list of your models.\n",
    "\n",
    "You have to manage the queue of fine-tuning task, because openai API is mostly busy.\n",
    "\n",
    "If the connection is weak or frequently missing, try use the direct call of API using os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-03 17:39:55] Created fine-tune: ft-no2aS78P1jatbjjghPLajFhZ\n",
      "[2023-05-03 17:40:08] Fine-tune failed. Fine-tune will exceed billing hard limit\n",
      "\n",
      "Job failed. Please contact support@openai.com if you need assistance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n{engines.list,engines.get,engines.update,engines.generate,completions.create,\\ndeployments.list,deployments.get,deployments.delete,deployments.create,models.list,\\nmodels.get,models.delete,files.create,files.get,files.delete,files.list,fine_tunes.list,\\nfine_tunes.create,fine_tunes.get,fine_tunes.results,fine_tunes.events,fine_tunes.follow,fine_tunes.cancel,\\nfine_tunes.delete,image.create,image.create_edit,image.create_variation}: invalid choice: 'fine_tunes.model' \\n(choose from 'engines.list', 'engines.get', 'engines.update', 'engines.generate', 'completions.create', \\n'deployments.list', 'deployments.get', 'deployments.delete', 'deployments.create', 'models.list', 'models.get', \\n'models.delete', 'files.create', 'files.get', 'files.delete', 'files.list', 'fine_tunes.list', 'fine_tunes.create', \\n'fine_tunes.get', 'fine_tunes.results', 'fine_tunes.events', 'fine_tunes.follow', 'fine_tunes.cancel', 'fine_tunes.delete', \\n'image.create', 'image.create_edit', 'image.create_variation')\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-no2aS78P1jatbjjghPLajFhZ\n",
    "#!openai api fine_tunes.list\n",
    "\"\"\"\n",
    "\n",
    "{engines.list,engines.get,engines.update,engines.generate,completions.create,\n",
    "deployments.list,deployments.get,deployments.delete,deployments.create,models.list,\n",
    "models.get,models.delete,files.create,files.get,files.delete,files.list,fine_tunes.list,\n",
    "fine_tunes.create,fine_tunes.get,fine_tunes.results,fine_tunes.events,fine_tunes.follow,fine_tunes.cancel,\n",
    "fine_tunes.delete,image.create,image.create_edit,image.create_variation}: invalid choice: 'fine_tunes.model' \n",
    "(choose from 'engines.list', 'engines.get', 'engines.update', 'engines.generate', 'completions.create', \n",
    "'deployments.list', 'deployments.get', 'deployments.delete', 'deployments.create', 'models.list', 'models.get', \n",
    "'models.delete', 'files.create', 'files.get', 'files.delete', 'files.list', 'fine_tunes.list', 'fine_tunes.create', \n",
    "'fine_tunes.get', 'fine_tunes.results', 'fine_tunes.events', 'fine_tunes.follow', 'fine_tunes.cancel', 'fine_tunes.delete', \n",
    "'image.create', 'image.create_edit', 'image.create_variation')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use the fine-tuned model for predicting non-observed data\n",
    "\n",
    "0. If the api key is missing, redefine the key\n",
    "openai.api_key = \"your key\"\n",
    "\n",
    "1. Prepare unlabelled dataset in a jsonl form (recommended), and apply your model to the unlabelled jsonl file.\n",
    "2. Stop token should be defined, which determines when the model stop to generate its output.\n",
    "3. Prompt is your input text, temperature is randomness (if you want to extract something without arbitrary generation, temp would be 0; top_p is similar to temperature, so use either one)\n",
    "4. Max token is the maximum length of your ideal output\n",
    "5. Not necessary; best_of is about how many answers the model consider before giving you final answer. frequency and presence penalty is about the provision of new topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "your_model = \"your model\"\n",
    "\n",
    "prompt = \"Text ==>\"\n",
    "\n",
    "\n",
    "result = openai.Completion.create(model=your_model, \n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_tokens=256,\n",
    "            #best_of=3,\n",
    "            #top_p=1,\n",
    "            stop=[\"\\n\\n###\\n\\n\"]\n",
    "            #frequency_penalty=0,\n",
    "            #presence_penalty=0.6\n",
    "            )\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62a502f04e82a0c0232d2caa1db61eaf987a42ad143f0e72c599831f18ad1b17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
